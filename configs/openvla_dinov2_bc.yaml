dataset:
  path: ./dataset
  train_split: train
  val_split: val
  batch_size: 16
  num_workers: 8
  sequence_length: 1
  normalize_proprio: true  # Normalizes 7 joint positions + adds normalized timestep (8th dim)
  cache_dataset: false

model:
  vision_encoder: facebook/dinov2-base
  language_encoder: bert-base-uncased
  fusion_hidden_dim: 768  # Increased from 512 for better spatial reasoning
  fusion_layers: 4  # Increased from 2 for stronger vision-action coupling
  action_dim: 8  # 7 joint positions + 1 gripper position
  max_instruction_tokens: 64
  freeze_vision: false  # CRITICAL: Allow vision encoder to learn task-specific features
  freeze_language: false
  dropout: 0.05  # Reduced from 0.1 to retain more learned features
  history_length: 5  # Number of past actions for closed-loop control

training:
  epochs: 35  # More epochs needed when fine-tuning vision encoder
  lr: 0.0001  # Increased from 0.00003 for better convergence with 350 episodes
  weight_decay: 0.01
  grad_clip: 5.0  # Increased to prevent gradient spikes during early training
  device: cuda
  seed: 42
  log_interval: 10
  val_interval: 1
  checkpoint_dir: ./runs
  checkpoint_name: dinov2_bc
  mixed_precision: true  # Enable for 2-3x speedup
  deterministic: false

evaluation:
  episodes_static: 50
  episodes_hindered: 50
  asset_root: ./env/mujoco_assets
  render: false  # Set to true for GUI visualization (slower)
